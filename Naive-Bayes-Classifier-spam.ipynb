{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f79f88",
   "metadata": {},
   "source": [
    "## SMS Spam Detection with Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad12eba",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "\n",
    "* SMS Spam Collection Dataset: https://archive.ics.uci.edu/dataset/228/sms+spam+collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74819d",
   "metadata": {},
   "source": [
    "<b>Model design: </b><br>\n",
    "\n",
    "Initial steps: \n",
    "\n",
    "1. Load dataset into dataframe.\n",
    "2. Split data into 80% train and 20% test set.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Training: \n",
    "\n",
    "1. Load train data into dataframe.\n",
    "2. Preprocess and tokenize train data.\n",
    "3. Group ham and spam class into two individual dataframe.\n",
    "4. Calculate the total number of documents in ham class $N_{h}$ and spam class $N_{s}$.\n",
    "5. Calculate the probability of ham class $\\widehat{P}(H)$ and spam class $\\widehat{P}(S)$.\n",
    "\n",
    "$$ \\widehat{P}(H) =  \\frac{N_{h}}{N_{h} + N_{s}} $$\n",
    "$$ \\widehat{P}(S) =  \\frac{N_{s}}{N_{h} + N_{s}} $$\n",
    "\n",
    "5. Create a vocabulary vector for each class and create the bag of word matrix of each class from the train data.\n",
    "6. Calculate the frequency for each vocab in each class and the probability of the word given its class.\n",
    "\n",
    "$$ n_{h}(w) = \\text{frequency of word w in class ham} $$ \n",
    "$$ n_{s}(w) = \\text{frequency of word w in class spam} $$\n",
    "$$ \\widehat{P}(w|H) =  \\frac{n_{h}(w)}{N_{h}} $$\n",
    "$$ \\widehat{P}(w|S) =  \\frac{n_{s}(w)}{N_{s}} $$\n",
    "\n",
    "7. Combine ham and spam dataframe along with its word frequency and probability.\n",
    "8. Missing values in the table are filled in with laplace add-one smoothing.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Testing: \n",
    "\n",
    "For Bag of Word method:\n",
    "\n",
    "1. Load test data into dataframe.\n",
    "2. Preprocess and tokenize test data.\n",
    "3. Create bag of words matrix for test data.\n",
    "4. Calculate probability of each class k given bow matrix of test data using Bayes theorem.\n",
    "\n",
    "$$ P(C_{k}|b) = P(b|C_{k})P(C_{k}) $$\n",
    "$$            = P(C_{k})\\prod_{i=1}^{V} [b_{i} P(w_{i}|C_{k}) + (1-b_{i})(1-P(w_{i}|C_{k}))] $$\n",
    "\n",
    "5. The class with the larger probability will be the predicted class.\n",
    "6. Evaluate model's performance with accuracy score.\n",
    "\n",
    "For Bag of Word and TF-IDF method:\n",
    "\n",
    "1. Load test data into dataframe.\n",
    "2. Preprocess and tokenize test data.\n",
    "3. Calculate tf-idf matrix for test data.\n",
    "\n",
    "$$ TF = \\frac{\\text{Number of times word appears in the document}}{\\text{Total number of words in the document}} $$\n",
    "\n",
    "$$ DF = \\text{Number of documents in the corpus that contains the word} $$\n",
    "\n",
    "$$ IDF = \\log{(\\frac{\\text{Total number of documents}}{DF})} $$\n",
    "\n",
    "$$ TFIDF = TF * IDF $$\n",
    "\n",
    "4. Normalize the tf-idf matrix.\n",
    "5. Calculate probability of each class k given tf-idf matrix of test data using Bayes theorem.\n",
    "6. The class with the larger probability will be the predicted class.\n",
    "7. Evaluate model's performance with accuracy score.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Evaluation metric:\n",
    "1. Accuracy score \n",
    "\n",
    "$$ acc = \\frac{\\text{Total number of correct predictions}}{\\text{Total predictions made}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd76ba",
   "metadata": {},
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2570138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4109920",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "load file and convert to dataframe and new list of only text content\n",
    "'''\n",
    "def load_file(filename: str):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().split(\"\\n\")\n",
    "        new_df = []\n",
    "        for line in text:\n",
    "            temp = line.split(\"\\t\")\n",
    "            # ignore empty lines\n",
    "            if len(temp) > 1:\n",
    "                new_df.append(temp)\n",
    "\n",
    "    dataframe = pd.DataFrame(new_df, columns=['label', 'content'])\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "''' \n",
    "tokenize text \n",
    "'''\n",
    "def split_token(line: list[str]):\n",
    "    cleaned_text = []\n",
    "    for i in line:\n",
    "        # ignore any empty sentences\n",
    "        if i == \"\":\n",
    "            continue\n",
    "        else:\n",
    "            # convert words to lower case to normalize\n",
    "            # split sentence into tokens\n",
    "            sentence = i.lower().split(\" \")\n",
    "            sentence = [word for word in sentence if word]\n",
    "            if sentence:\n",
    "                cleaned_text.append(sentence)\n",
    "                \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "''' \n",
    "pre-process data \n",
    "'''\n",
    "def process_data(line: list[list[str]]):\n",
    "    for s in range(len(line)):\n",
    "        clean = []\n",
    "        for word in line[s]:\n",
    "            # filter each word to ignore punctuations\n",
    "            new = ''.join(char for char in word if char not in string.punctuation)\n",
    "            clean.append(new)\n",
    "        # ignore empty strings\n",
    "        clean = [i for i in clean if i]\n",
    "        line[s] = clean\n",
    "        \n",
    "    return line\n",
    "\n",
    "\n",
    "''' \n",
    "create vocab dictionary \n",
    "'''\n",
    "def make_vocab(data: list[str]):\n",
    "    vocab = []\n",
    "    for sentence in data:\n",
    "        for word in sentence:\n",
    "            if word in vocab:\n",
    "                continue\n",
    "            else:\n",
    "                vocab.append(word)\n",
    "                \n",
    "    return vocab\n",
    "\n",
    "\n",
    "'''\n",
    "create bag of words vector \n",
    "'''\n",
    "def make_bag_of_words(data: list[list[str]], vocab: list):  \n",
    "    bow = []\n",
    "    for line in data:\n",
    "        curr_bow = [1 if i in line else 0 for i in vocab]\n",
    "        bow.append(curr_bow)\n",
    "    \n",
    "    return np.array(bow) \n",
    "\n",
    "\n",
    "'''\n",
    "create BoW matrix for each class\n",
    "'''\n",
    "def get_class_matrix(class1_df, class2_df):\n",
    "    # ham\n",
    "    # process data in ham\n",
    "    ham_content = class1_df['X_train'].to_list()\n",
    "    ham_content = split_token(ham_content)\n",
    "    ham_content = process_data(ham_content)\n",
    "    \n",
    "    # get ham vocab\n",
    "    ham_vocab = make_vocab(ham_content)\n",
    "    \n",
    "    # create bag of words for ham class\n",
    "    ham_bow = make_bag_of_words(ham_content, ham_vocab)\n",
    "    \n",
    "    # spam\n",
    "    # process data in ham\n",
    "    spam_content = class2_df['X_train'].to_list()\n",
    "    spam_content = split_token(spam_content)\n",
    "    spam_content = process_data(spam_content)\n",
    "    \n",
    "    # get spam vocab\n",
    "    spam_vocab = make_vocab(spam_content)\n",
    "    \n",
    "    # create bag of words for spam class\n",
    "    spam_bow = make_bag_of_words(spam_content, spam_vocab)\n",
    "    \n",
    "    return ham_vocab, spam_vocab, ham_bow, spam_bow\n",
    "\n",
    "\n",
    "'''\n",
    "calculate DF\n",
    "'''\n",
    "def calc_df(df, vocab):\n",
    "    df_dict = {}\n",
    "    for word in vocab:\n",
    "        count = df[df['X_test'].str.contains(word)].shape[0]\n",
    "        df_dict[word] = count\n",
    "        \n",
    "    return df_dict\n",
    "\n",
    "\n",
    "'''\n",
    "calculate TF-IDF\n",
    "'''\n",
    "def calc_tfidf(word, doc, total_doc, df_dict):\n",
    "    tf = doc.count(word) / len(doc)\n",
    "    df = df_dict[word]\n",
    "    # add one to denominator to avoid division by 0\n",
    "    idf = np.log(total_doc / (df + 1))\n",
    "    return tf * idf\n",
    "\n",
    "\n",
    "'''\n",
    "create TF-IDF matrix\n",
    "'''\n",
    "def get_tfidf_matrix(vocab, data, df_dict):\n",
    "    tfidf_matrix = []\n",
    "    total_doc = len(data)\n",
    "    for doc in data:\n",
    "        vector = [calc_tfidf(word, doc, total_doc, df_dict) for word in vocab]\n",
    "        tfidf_matrix.append(vector)\n",
    "        \n",
    "    return np.array(tfidf_matrix)\n",
    "    \n",
    "    \n",
    "'''\n",
    "Train the model\n",
    "'''\n",
    "def train(n1, n2, vocab1, vocab2, bow1, bow2):\n",
    "    # get total number of each vocab in each class\n",
    "    n_ham_w = np.sum(bow1, axis=0)\n",
    "    n_spam_w = np.sum(bow2, axis=0)\n",
    "    \n",
    "    # get probability of each vocab in each class\n",
    "    p_w_ham = np.array(n_ham_w) / n1\n",
    "    p_w_spam = np.array(n_spam_w) / n2\n",
    "    \n",
    "    # arrange into dataframe\n",
    "    ham_prob_df = pd.DataFrame(np.vstack([vocab1, n_ham_w, p_w_ham]).T, columns=['word', 'n_ham(word)', 'P(word|ham)'])\n",
    "    spam_prob_df = pd.DataFrame(np.vstack([vocab2, n_spam_w, p_w_spam]).T, columns=['word', 'n_spam(word)', 'P(word|spam)'])\n",
    "    \n",
    "    return ham_prob_df, spam_prob_df\n",
    "\n",
    "\n",
    "'''\n",
    "Test the model \n",
    "'''\n",
    "def test(data, vocab, merged, p_ham, p_spam, tfidf_method=False, df_dict=None):\n",
    "    # pre-process test data\n",
    "    data = data['X_test'].to_list()\n",
    "    data = split_token(data)\n",
    "    data = process_data(data)\n",
    "    \n",
    "    p_w_ham = merged['P(word|ham)'].astype(float).to_numpy()\n",
    "    p_w_spam = merged['P(word|spam)'].astype(float).to_numpy()\n",
    "    \n",
    "    # Bag of Word method\n",
    "    if tfidf_method is False:\n",
    "        # create bag of words\n",
    "        test_bow = make_bag_of_words(data, vocab)\n",
    "        \n",
    "        # calculate probability of sentence being classified as ham or spam\n",
    "        curr_ham_prob = np.sum(np.log2(test_bow * p_w_ham + (1 - test_bow) * (1 - p_w_ham)), axis=1)\n",
    "        curr_spam_prob = np.sum(np.log2(test_bow * p_w_spam + (1 - test_bow) * (1 - p_w_spam)), axis=1)\n",
    "        \n",
    "    # TF-IDF method\n",
    "    if tfidf_method is True:\n",
    "        # create tf-idf matrix\n",
    "        tfidf_matrix = get_tfidf_matrix(vocab, data, df_dict)\n",
    "        \n",
    "        # normalize matrix\n",
    "        tfidf_norm = np.linalg.norm(tfidf_matrix)\n",
    "        tfidf_matrix = tfidf_matrix / tfidf_norm\n",
    "        \n",
    "        # calculate probability of sentence being classified as ham or spam\n",
    "        curr_ham_prob = np.sum(np.log2(tfidf_matrix * p_w_ham + (1 - tfidf_matrix) * (1 - p_w_ham)), axis=1)\n",
    "        curr_spam_prob = np.sum(np.log2(tfidf_matrix * p_w_spam + (1 - tfidf_matrix) * (1 - p_w_spam)), axis=1)\n",
    "    \n",
    "    ham_prob = np.log2(p_ham) + curr_ham_prob\n",
    "    spam_prob = np.log2(p_spam) + curr_spam_prob\n",
    "    \n",
    "    # predict if ham or spam\n",
    "    predicted = np.where(ham_prob > spam_prob, \"ham\", \"spam\").tolist()\n",
    "\n",
    "    return predicted\n",
    "\n",
    "\n",
    "'''\n",
    "Evaluate Accuracy Score \n",
    "'''\n",
    "def evaluate(data):\n",
    "    total_rows = data.shape[0]\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        if row['y_test'] == row['predicted']:\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    accuracy = correct_predictions / total_rows\n",
    "    return accuracy\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cae961",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb55dd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            content\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5570   ham               Will ü b going to esplanade fr home?\n",
       "5571   ham  Pity, * was in mood for that. So...any other s...\n",
       "5572   ham  The guy did some bitching but I acted like i'd...\n",
       "5573   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load original dataframe\n",
    "\n",
    "df = load_file(\"SMSSpamCollection\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ba663",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04fdbc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to 80% train and 20% test data\n",
    "\n",
    "X = df.iloc[:, 1]\n",
    "y = df.iloc[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9040727f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef5d633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_train</th>\n",
       "      <th>X_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>spam</td>\n",
       "      <td>FREE2DAY sexy St George's Day pic of Jordan!Tx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>ham</td>\n",
       "      <td>Armand says get your ass over to epsilon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol now I'm after that hot air balloon!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>ham</td>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>ham</td>\n",
       "      <td>Good morning, my Love ... I go to sleep now an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi, wlcome back, did wonder if you got eaten b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>spam</td>\n",
       "      <td>ree entry in 2 a weekly comp for a chance to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"OH FUCK. JUSWOKE UP IN A BED ON A BOATIN THE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>ham</td>\n",
       "      <td>NOT MUCH NO FIGHTS. IT WAS A GOOD NITE!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did he just say somebody is named tampa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_train                                            X_train\n",
       "1350    spam  FREE2DAY sexy St George's Day pic of Jordan!Tx...\n",
       "5544     ham           Armand says get your ass over to epsilon\n",
       "1168     ham            Lol now I'm after that hot air balloon!\n",
       "5551     ham  You know, wot people wear. T shirts, jumpers, ...\n",
       "5320     ham  Good morning, my Love ... I go to sleep now an...\n",
       "...      ...                                                ...\n",
       "3772     ham  Hi, wlcome back, did wonder if you got eaten b...\n",
       "5191    spam  ree entry in 2 a weekly comp for a chance to w...\n",
       "5226     ham  \"OH FUCK. JUSWOKE UP IN A BED ON A BOATIN THE ...\n",
       "5390     ham           NOT MUCH NO FIGHTS. IT WAS A GOOD NITE!!\n",
       "860      ham            Did he just say somebody is named tampa\n",
       "\n",
       "[4459 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load train dataframe\n",
    "\n",
    "train_df = pd.DataFrame({\"y_train\": y_train, \"X_train\": X_train})\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d526065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to ham and spam dataframe\n",
    "\n",
    "ham_df = train_df[train_df[\"y_train\"]==\"ham\"]\n",
    "n_ham = ham_df.shape[0]\n",
    "p_ham = float(n_ham / train_df.shape[0])\n",
    "\n",
    "spam_df = train_df[train_df[\"y_train\"]==\"spam\"]\n",
    "n_spam = spam_df.shape[0]\n",
    "p_spam = float(n_spam / train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e644771",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_vocab, spam_vocab, ham_bow, spam_bow = get_class_matrix(ham_df, spam_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25324e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>n_ham(word)</th>\n",
       "      <th>P(word|ham)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>armand</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000774593338497289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>says</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0059385489284792155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get</td>\n",
       "      <td>225</td>\n",
       "      <td>0.05809450038729667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your</td>\n",
       "      <td>289</td>\n",
       "      <td>0.07461915827523884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ass</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003098373353989156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6727</th>\n",
       "      <td>docks</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0002581977794990963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0002581977794990963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6729</th>\n",
       "      <td>spinout</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0002581977794990963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730</th>\n",
       "      <td>gossip</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0002581977794990963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6731</th>\n",
       "      <td>fights</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0002581977794990963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6732 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word n_ham(word)            P(word|ham)\n",
       "0      armand           3   0.000774593338497289\n",
       "1        says          23  0.0059385489284792155\n",
       "2         get         225    0.05809450038729667\n",
       "3        your         289    0.07461915827523884\n",
       "4         ass          12   0.003098373353989156\n",
       "...       ...         ...                    ...\n",
       "6727    docks           1  0.0002581977794990963\n",
       "6728       25           1  0.0002581977794990963\n",
       "6729  spinout           1  0.0002581977794990963\n",
       "6730   gossip           1  0.0002581977794990963\n",
       "6731   fights           1  0.0002581977794990963\n",
       "\n",
       "[6732 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_prob_df, spam_prob_df = train(n_ham, n_spam, ham_vocab, spam_vocab, ham_bow, spam_bow)\n",
    "ham_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "430be971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>n_spam(word)</th>\n",
       "      <th>P(word|spam)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>free2day</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0034129692832764505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexy</td>\n",
       "      <td>9</td>\n",
       "      <td>0.015358361774744027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>st</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0034129692832764505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>georges</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0034129692832764505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>day</td>\n",
       "      <td>10</td>\n",
       "      <td>0.017064846416382253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>lotr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0017064846416382253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>june</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0017064846416382253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>soundtrack</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0017064846416382253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>stdtxtrate</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0017064846416382253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>ree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0017064846416382253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2710 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word n_spam(word)           P(word|spam)\n",
       "0       free2day            2  0.0034129692832764505\n",
       "1           sexy            9   0.015358361774744027\n",
       "2             st            2  0.0034129692832764505\n",
       "3        georges            2  0.0034129692832764505\n",
       "4            day           10   0.017064846416382253\n",
       "...          ...          ...                    ...\n",
       "2705        lotr            1  0.0017064846416382253\n",
       "2706        june            1  0.0017064846416382253\n",
       "2707  soundtrack            1  0.0017064846416382253\n",
       "2708  stdtxtrate            1  0.0017064846416382253\n",
       "2709         ree            1  0.0017064846416382253\n",
       "\n",
       "[2710 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e455a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>n_ham(word)</th>\n",
       "      <th>P(word|ham)</th>\n",
       "      <th>n_spam(word)</th>\n",
       "      <th>P(word|spam)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>armand</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000774593338497289</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>says</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0059385489284792155</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get</td>\n",
       "      <td>225</td>\n",
       "      <td>0.05809450038729667</td>\n",
       "      <td>57</td>\n",
       "      <td>0.09726962457337884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your</td>\n",
       "      <td>289</td>\n",
       "      <td>0.07461915827523884</td>\n",
       "      <td>174</td>\n",
       "      <td>0.29692832764505117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ass</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003098373353989156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>nowreply</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0017064846416382253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8516</th>\n",
       "      <td>lotr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0017064846416382253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517</th>\n",
       "      <td>soundtrack</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0017064846416382253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>stdtxtrate</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0017064846416382253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8519</th>\n",
       "      <td>ree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0017064846416382253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8520 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word n_ham(word)            P(word|ham) n_spam(word)  \\\n",
       "0         armand           3   0.000774593338497289            1   \n",
       "1           says          23  0.0059385489284792155            1   \n",
       "2            get         225    0.05809450038729667           57   \n",
       "3           your         289    0.07461915827523884          174   \n",
       "4            ass          12   0.003098373353989156            1   \n",
       "...          ...         ...                    ...          ...   \n",
       "8515    nowreply           1               0.000258            1   \n",
       "8516        lotr           1               0.000258            1   \n",
       "8517  soundtrack           1               0.000258            1   \n",
       "8518  stdtxtrate           1               0.000258            1   \n",
       "8519         ree           1               0.000258            1   \n",
       "\n",
       "               P(word|spam)  \n",
       "0                  0.001706  \n",
       "1                  0.001706  \n",
       "2       0.09726962457337884  \n",
       "3       0.29692832764505117  \n",
       "4                  0.001706  \n",
       "...                     ...  \n",
       "8515  0.0017064846416382253  \n",
       "8516  0.0017064846416382253  \n",
       "8517  0.0017064846416382253  \n",
       "8518  0.0017064846416382253  \n",
       "8519  0.0017064846416382253  \n",
       "\n",
       "[8520 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge train ham and spam dataframe\n",
    "\n",
    "merged_df = ham_prob_df.merge(spam_prob_df, on='word', how='outer')\n",
    "\n",
    "# fill in unseen data with Laplace add one smoothing\n",
    "merged_df['n_ham(word)'].fillna(1, inplace=True)\n",
    "merged_df['P(word|ham)'].fillna(float(1/n_ham), inplace=True)\n",
    "merged_df['n_spam(word)'].fillna(1, inplace=True)\n",
    "merged_df['P(word|spam)'].fillna(float(1/n_spam), inplace=True)\n",
    "\n",
    "# rearrange columns\n",
    "merged_df = merged_df[['word', 'n_ham(word)', 'P(word|ham)', 'n_spam(word)', 'P(word|spam)']]\n",
    "\n",
    "# get list of vocab in training set\n",
    "train_vocab = merged_df['word'].to_list()\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f69d2a8",
   "metadata": {},
   "source": [
    "### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d3a167d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>X_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>ham</td>\n",
       "      <td>You still coming tonight?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ya even those cookies have jelly on them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry i've not gone to that place. I.ll do so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>ham</td>\n",
       "      <td>When are you going to ride your bike?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>ham</td>\n",
       "      <td>My supervisor find 4 me one lor i thk his stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>spam</td>\n",
       "      <td>Bored housewives! Chat n date now! 0871750.77....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rose for red,red for blood,blood for heart,hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>ham</td>\n",
       "      <td>Also remember the beads don't come off. Ever.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hey Boys. Want hot XXX pics sent direct 2 ur p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test                                             X_test\n",
       "3690    ham                          You still coming tonight?\n",
       "3527    ham  \"HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...\n",
       "724     ham           Ya even those cookies have jelly on them\n",
       "3370    ham  Sorry i've not gone to that place. I.ll do so ...\n",
       "468     ham              When are you going to ride your bike?\n",
       "...     ...                                                ...\n",
       "2942    ham  My supervisor find 4 me one lor i thk his stud...\n",
       "4864   spam  Bored housewives! Chat n date now! 0871750.77....\n",
       "3227    ham  Rose for red,red for blood,blood for heart,hea...\n",
       "3796    ham      Also remember the beads don't come off. Ever.\n",
       "2879   spam  Hey Boys. Want hot XXX pics sent direct 2 ur p...\n",
       "\n",
       "[1115 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test dataframe\n",
    "\n",
    "test_df = pd.DataFrame({\"y_test\": y_test, \"X_test\": X_test})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8794086",
   "metadata": {},
   "source": [
    "#### Test using only Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de5bf874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>X_test</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>ham</td>\n",
       "      <td>You still coming tonight?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ya even those cookies have jelly on them</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry i've not gone to that place. I.ll do so ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>ham</td>\n",
       "      <td>When are you going to ride your bike?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>ham</td>\n",
       "      <td>My supervisor find 4 me one lor i thk his stud...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>spam</td>\n",
       "      <td>Bored housewives! Chat n date now! 0871750.77....</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rose for red,red for blood,blood for heart,hea...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>ham</td>\n",
       "      <td>Also remember the beads don't come off. Ever.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hey Boys. Want hot XXX pics sent direct 2 ur p...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test                                             X_test predicted\n",
       "3690    ham                          You still coming tonight?       ham\n",
       "3527    ham  \"HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...       ham\n",
       "724     ham           Ya even those cookies have jelly on them       ham\n",
       "3370    ham  Sorry i've not gone to that place. I.ll do so ...       ham\n",
       "468     ham              When are you going to ride your bike?       ham\n",
       "...     ...                                                ...       ...\n",
       "2942    ham  My supervisor find 4 me one lor i thk his stud...       ham\n",
       "4864   spam  Bored housewives! Chat n date now! 0871750.77....      spam\n",
       "3227    ham  Rose for red,red for blood,blood for heart,hea...      spam\n",
       "3796    ham      Also remember the beads don't come off. Ever.       ham\n",
       "2879   spam  Hey Boys. Want hot XXX pics sent direct 2 ur p...      spam\n",
       "\n",
       "[1115 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict test data\n",
    "\n",
    "predicted_res = test(test_df, train_vocab, merged_df, p_ham, p_spam, tfidf_method=False)\n",
    "\n",
    "res_bow_df = test_df.assign(predicted=predicted_res)\n",
    "res_bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3a765b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy using Bag of Words method: 0.9748878923766816\n"
     ]
    }
   ],
   "source": [
    "# calculate predicted test accuracy\n",
    "\n",
    "test_acc_bow = evaluate(res_bow_df)\n",
    "print(f'Test Accuracy using Bag of Words method: {test_acc_bow}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4684f167",
   "metadata": {},
   "source": [
    "#### Test with Bag of Words and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "052d094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_records = calc_df(test_df, train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b7f9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>X_test</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>ham</td>\n",
       "      <td>You still coming tonight?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ya even those cookies have jelly on them</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry i've not gone to that place. I.ll do so ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>ham</td>\n",
       "      <td>When are you going to ride your bike?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>ham</td>\n",
       "      <td>My supervisor find 4 me one lor i thk his stud...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>spam</td>\n",
       "      <td>Bored housewives! Chat n date now! 0871750.77....</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rose for red,red for blood,blood for heart,hea...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>ham</td>\n",
       "      <td>Also remember the beads don't come off. Ever.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hey Boys. Want hot XXX pics sent direct 2 ur p...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test                                             X_test predicted\n",
       "3690    ham                          You still coming tonight?       ham\n",
       "3527    ham  \"HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...       ham\n",
       "724     ham           Ya even those cookies have jelly on them       ham\n",
       "3370    ham  Sorry i've not gone to that place. I.ll do so ...       ham\n",
       "468     ham              When are you going to ride your bike?       ham\n",
       "...     ...                                                ...       ...\n",
       "2942    ham  My supervisor find 4 me one lor i thk his stud...       ham\n",
       "4864   spam  Bored housewives! Chat n date now! 0871750.77....       ham\n",
       "3227    ham  Rose for red,red for blood,blood for heart,hea...       ham\n",
       "3796    ham      Also remember the beads don't come off. Ever.       ham\n",
       "2879   spam  Hey Boys. Want hot XXX pics sent direct 2 ur p...       ham\n",
       "\n",
       "[1115 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict test data\n",
    "\n",
    "predicted_res1 = test(test_df, train_vocab, merged_df, p_ham, p_spam, tfidf_method=True, df_dict=df_records)\n",
    "\n",
    "res_tfidf_df = test_df.assign(predicted=predicted_res1)\n",
    "res_tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdc09e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy using Bag of Words and TF-IDF method: 0.8556053811659193\n"
     ]
    }
   ],
   "source": [
    "# calculate predicted test accuracy\n",
    "\n",
    "test_acc_tfidf = evaluate(res_tfidf_df)\n",
    "print(f'Test Accuracy using Bag of Words and TF-IDF method: {test_acc_tfidf}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
